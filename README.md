# SuperCLUE

中文通用大模型综合性基准SuperCLUE

<a href='https://www.superclueai.com' target="__blank">榜单地址</a>

公众号文章：<a href='https://mp.weixin.qq.com/s/iKkohLPlAj4Hi0QUeaSL3A'>SuperCLUE中文大模型测评基准11月榜单发布</a>

官网地址：<a href='https://www.cluebenchmarks.com/superclue.html' target="__blank">www.cluebenchmarks.com/superclue.html</a>

技术报告：<a href='https://arxiv.org/abs/2307.15020' target="__blank">SuperCLUE: A Comprehensive Chinese Large Language Model Benchmark</a>


【2023-11-28】 <a href='https://mp.weixin.qq.com/s/Wd0NiIZPJMZk52UneGTyfQ'>《中文大模型测评报告，2023》发布</a>

【2023-11-30】 发布SuperCLUE-2023年11月榜单


【2023-10-19】 <a href='https://www.cluebenchmarks.com/superclue_agent.html' target="__blank">SuperCLUE-Agent：Agent智能体中文原生任务评估基准</a>


【2023-9-12】 <a href='https://github.com/CLUEbenchmark/SuperCLUE-safety' target="__blank">SuperCLUE-Safety：中文大模型多轮对抗安全基准</a>


【2023-9-26】，SuperCLUE发布中文大模型9月榜单。

SuperCLUE是一个综合性大模型评测基准，本次评测主要聚焦于大模型的四个能力象限，包括语言理解与生成、专业技能与知识、Agent智能体和安全性，进而细化为12项基础能力。

相比与上月，新增了AI Agent智能体

<img src="https://github.com/CLUEbenchmark/SuperCLUE/blob/main/resources/superclue_idea2.png"  width="90%" height="90%"></img>

### SuperCLUE能力评估结构图
<img src="https://github.com/CLUEbenchmark/SuperCLUE/blob/main/resources/category09.png"  width="60%" height="60%"></img>

### SuperCLUE多维度测评方案
<img src="https://github.com/CLUEbenchmark/SuperCLUE/blob/main/resources/r2309/superclue_mlitisystem.png"  width="90%" height="90%"></img>


### 为什么新增AI Agent智能体能力？

AI agent（智能体）是当前与大语言模型相关的前沿研究热点，拥有类似贾维斯等科幻电影中人类超级助手的能力，可以根据需求自主的完成任务。
然而，面向AI agent智能体，缺乏针对中文大模型的广泛评估。为了解决这一问题，我们在SuperCLUE新的榜单中新增了AI agent智能体能力的测评。
这个榜单将重点评估AI agent在【工具使用】和【任务规划】两个关键能力上的表现，这项工作旨在为评估中文大模型作为智能体的表现提供一个基础和可能。

### SuperCLUE总排行榜（2023年11月）

| 排名 | 模型 | 机构 | 总分 | OPEN<br>开放多轮 | OPT<br>客观题 | 使用 |
|:---:|:---:|:---:|:---:|:---:|:---:|:---:|  
| - | GPT4-Turbo | OpenAI | 89.79 | 97.53 | 78.18 | API |
| - | GPT-4 | OpenAI | 75.14 | 73.01 | 78.33 | API |
| 🏅️ | 文心一言4.0 | 百度 | 74.02 | 73.62 | 74.61 | API |  
| 🥈| Moonshot | 月之暗面 | 72.88 | 71.47 | 74.99 | 网页 |
| 🥉 | Yi-34B-Chat|	零一万物|	71.87|	71.21|	72.85|	模型|
| 4 | BlueLM | vivo | 67.14 | 64.88 | 70.53 | API |  
| 5 | 腾讯混元 | 腾讯 | 66.96 | 62.27 | 74.00 | API |
| 5 | 通义千问2.0(v1030) | 阿里巴巴 | 66.94 | 61.01 | 75.83 | API |
| 7 | ChatGLM3-Turbo | 清华&智谱 | 66.50 | 63.27 | 71.34 | API |
| - | Claude2 | Anthropic | 60.62 | 57.82 | 64.82 | API |
| 8 | 云雀大模型(豆包) | 字节跳动 | 60.42 | 55.96 | 67.11 | 网页 |
| - | GPT3.5-Turbo | OpenAI | 59.39 | 57.16 | 62.73 | API |  
| 9 | XVERSE-13B-2-Chat | 元象科技 | 58.31 | 49.95 | 70.84 | 模型 |
| 10 | Qwen-14B-Chat | 阿里巴巴 | 57.90 | 49.05 | 71.18 | API |
| 11 | 讯飞星火V3.0 | 科大讯飞 | 57.18 | 51.00 | 66.45 | API | 
| 12 | Baichuan2-13B-Chat | 百川智能 | 56.33 | 50.33 | 65.33 | 模型 |
| 13 | MiniMax-Abab5.5 | MiniMax | 55.08 | 45.27 | 69.80 | API |
| 14 | 360GPT_S2_V10 | 360 | 46.47 | 33.35 | 66.14 | API |
| 15 | ChatGLM3-6B | 清华&智谱 | 46.24 | 38.01 | 58.58 | 模型 |
| 16 | Chinese-Alpaca-2-13B | yiming cui | 43.42 | 38.09 | 51.42 | 模型 |
| - | Llama-2-13B-Chat | Meta | 31.47 | 28.67 | 35.67 | 模型 |
 
注：处于前列的模型，如果分数比较接近（小于0.03分），在排名时会被记为并列的名称。

### SuperCLUE-OPEN多轮开放问题排行榜（2023年11月）

| 排名 | 模型 | 机构 | OPEN<br/>总分 | 语言理解<br/>与生成 | 专业技能<br/>与知识 | 工具<br/>使用 | 传统<br/>安全 | 使用 | 
|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|
| - | GPT4-Turbo | OpenAI | 97.53 | 90.27 | 93.98 | 100.00 | 62.05 | API |
| 🏅️ | 文心一言4.0 | 百度 | 73.62 | 65.18 | 81.74 | 90.38 | 58.11 | API | 
| - | GPT-4 | OpenAI | 73.01 | 69.87 | 80.02 | 86.06 | 46.88 | API | 
| 🥈| Moonshot | 月之暗面 | 71.47 | 72.32 | 72.44 | 86.54 | 51.34 | 网页 |
|🥉  | Yi-34B-Chat | 	零一万物 | 	71.21  | 	74.60  | 	64.83 |  	87.98 |  	65.77  | 	模型   | 
| 4 | BlueLM | vivo | 64.88 | 65.58 | 64.30 | 70.71 | 58.04 | API |  
| 5 | ChatGLM3-Turbo | 清华&智谱 | 63.27 | 74.78 | 54.58 | 66.50 | 45.00 | API |
| 6 | 腾讯混元 | 腾讯 | 62.27 | 57.95 | 64.46 | 77.88 | 54.13 | API |
| 7 | 通义千问2.0(v1030) | 阿里巴巴 | 61.01 | 47.79 | 72.62 | 74.04 | 52.68 | API |
| - | Claude2 | Anthropic | 57.82 | 47.72 | 66.18 | 51.49 | 69.72 | API |
| - | GPT3.5-Turbo | OpenAI | 57.16 | 58.59 | 56.69 | 59.62 | 51.79 | API |  
| 8 | 云雀大模型(豆包) | 字节跳动 | 55.96 | 49.20 | 60.92 | 51.92 | 63.84 | 网页 |
| 9 | 讯飞星火V3.0 | 科大讯飞 | 51.00 | 44.50 | 57.64 | 46.60 | 54.02 | API |
| 10 | Baichuan2-13B-Chat | 百川智能 | 50.33 | 51.86 | 45.38 | 65.38 | 48.64 | 模型 |
| 11 | XVERSE-13B-2-Chat | 元象科技 | 49.95 | 50.65 | 47.86 | 53.92 | 51.80 | 模型 |
| 12 | Qwen-14B-Chat | 阿里巴巴 | 49.05 | 41.99 | 53.31 | 50.96 | 56.02 | API |
| 13 | MiniMax-Abab5.5 | MiniMax | 45.27 | 38.00 | 51.32 | 60.58 | 32.59 | API |
| 14 | Chinese-Alpaca-2-13B | yiming cui | 38.09 | 43.51 | 32.14 | 34.13 | 42.86 | 模型 |
| 15 | ChatGLM3-6B | 清华&智谱 | 38.01 | 36.46 | 36.55 | 33.33 | 53.64 | 模型 |
| 16 | 360GPT_S2_V10 | 360 | 33.35 | 35.54 | 29.42 | 34.62 | 38.39 | API |  
| - | Llama-2-13B-Chat | Meta | 28.67 | 28.86 | 25.21 | 28.85 | 41.28 | 模型 |


### SuperCLUE-OPT三大能力客观题排行榜（2023年11月）

|排名|模型|机构|OPT<br/>分数|基础<br/>能力|中文<br/>特性|学术专业<br/>能力|使用<br/>方式|
|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|  
|-|GPT-4|OpenAI|78.33|83.51|79.29|72.04|API|
|-|GPT4-Turbo|OpenAI|78.18|80.68|79.20|74.57|API|
|🏅️|通义千问2.0(v1030)|阿里巴巴|75.83|79.89|81.83|65.39|API|
|🥈|Moonshot|月之暗面|74.99|78.89|80.55|64.99|网页|  
|🥉|文心一言4.0|百度|74.61|78.65|81.28|63.48|API|
|4|腾讯混元|腾讯|74.00|79.25|81.32|60.91|API|  
|5|Yi-34B-Chat|零一万物|72.85|73.65|79.98|63.00|模型|
|6|ChatGLM3-Turbo|清华&智谱|71.34|74.41|77.67|61.53|API|
|7|Qwen-14B-Chat|阿里巴巴|71.18|77.30|78.42|57.09|API|
|8|XVERSE-13B-2-Chat|元象科技|70.84|76.48|78.32|57.05|模型|
|9|BlueLM|vivo|70.53|75.05|76.85|59.31|API|  
|10|MiniMax-Abab5.5|MiniMax|69.80|73.47|76.20|59.35|API|
|11|云雀大模型(豆包)|字节跳动|67.11|70.53|72.12|58.32|网页|
|12|讯飞星火V3.0|科大讯飞|66.45|70.48|73.81|54.44|API|
|13|360GPT_S2_V10|360|66.14|72.52|72.42|53.05|API|
|14|Baichuan2-13B-Chat|百川智能|65.33|68.79|75.05|51.58|模型|
|-|Claude2|Anthropic|64.82|71.01|65.16|58.21|API|
|-|GPT3.5-Turbo|OpenAI|62.73|72.27|63.71|52.10|API|
|15|ChatGLM3-6B|清华&智谱|58.58|63.54|64.95|46.85|模型|  
|16|Chinese-Alpaca-2-13B|yiming cui|51.42|60.82|54.31|38.90|模型|
|-|Llama-2-13B-Chat|Meta|35.67|42.99|32.64|31.58|模型|



### SuperCLUE十大基础能力排行榜（2023年11月）

| 模型 | 计算 | 逻辑<br/>推理 | 代码 | 知识<br/>百科 | 语言<br/>理解 | 生成<br/>创作 | 对话 | 角色<br/>扮演 | 工具<br/>使用 | 传统<br/>安全 |
|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|  
| GPT4-Turbo | 92.13 | 100.00 | 100.00 | 83.78 | 77.27 | 100.00 | 83.82 | 100.00 | 100.00 | 62.05 |
| GPT-4 | 86.45 | 92.57 | 69.90 | 71.17 | 66.97 | 68.75 | 63.37 | 80.39 | 86.06 | 46.88 |
| 文心一言4.0 | 70.37 | 87.76 | 77.40 | 91.44 | 68.06 | 76.92 | 51.50 | 64.22 | 90.38 | 58.11 |
| Moonshot | 59.81 | 78.22 | 65.87 | 85.85 | 65.74 | 72.55 | 75.00 | 75.98 | 86.54 | 51.34 |
| Yi-34B-Chat | 	45.33 |  	76.73  | 	58.25  | 	79.02 | 	64.09  | 	100.00  | 	69.12 |  	65.20  | 	87.98 |  	65.77 |
| BlueLM | 50.00 | 79.41 | 44.90 | 82.88 | 59.17 | 68.27 | 57.92 | 76.96 | 70.71 | 58.04 |
| ChatGLM3-Turbo | 35.19 | 62.50 | 48.56 | 72.07 | 63.89 | 64.42 | 70.79 | 100.00 | 66.50 | 45.00 |
| 腾讯混元 | 44.39 | 62.87 | 64.42 | 86.16 | 62.27 | 54.33 | 46.57 | 68.63 | 77.88 | 54.13 |  
| 通义千问2.0(v1030) | 60.19 | 75.98 | 64.56 | 89.73 | 62.84 | 30.77 | 42.65 | 54.90 | 74.04 | 52.68 |
| Claude2 | 61.57 | 79.50 | 60.58 | 63.06 | 65.14 | 26.70 | 53.43 | 45.59 | 51.49 | 69.72 |
| GPT3.5-Turbo | 60.19 | 59.50 | 54.81 | 52.25 | 54.55 | 63.94 | 50.50 | 65.35 | 59.62 | 51.79 |
| 云雀大模型(豆包) | 48.13 | 66.67 | 35.58 | 93.30 | 54.09 | 40.87 | 43.00 | 58.82 | 51.92 | 63.84 |  
| 讯飞星火V3.0 | 38.79 | 66.16 | 42.72 | 82.87 | 54.13 | 31.73 | 37.25 | 54.90 | 46.60 | 54.02 |
| Baichuan2-13B-Chat | 22.69 | 59.90 | 28.85 | 70.09 | 57.73 | 39.90 | 53.43 | 56.37 | 65.38 | 48.64 |
| XVERSE-13B-2-Chat | 33.33 | 54.90 | 36.54 | 66.67 | 49.55 | 36.54 | 48.02 | 68.50 | 53.92 | 51.80 |
| Qwen-14B-Chat | 45.33 | 53.43 | 40.38 | 74.09 | 57.48 | 28.64 | 33.33 | 48.51 | 50.96 | 56.02 |
| MiniMax-Abab5.5 | 27.10 | 43.63 | 47.60 | 86.94 | 52.29 | 28.64 | 35.78 | 35.29 | 60.58 | 32.59 |
| Chinese-Alpaca-2-13B | 17.13 | 47.03 | 12.62 | 51.79 | 54.09 | 32.21 | 39.22 | 48.53 | 34.13 | 42.86 |
| ChatGLM3-6B | 22.22 | 51.06 | 27.40 | 45.50 | 49.08 | 19.61 | 35.15 | 42.00 | 33.33 | 53.64 |
| 360GPT_S2_V10 | 21.30 | 45.54 | 13.46 | 37.39 | 50.46 | 24.52 | 34.16 | 33.00 | 34.62 | 38.39 |
| Llama-2-13B-Chat | 14.02 | 49.49 | 10.10 | 27.23 | 35.91 | 33.17 | 15.46 | 30.88 | 28.85 | 41.28 |

### SuperCLUE开源模型排行榜（2023年11月）

| 排名 | 模型 | 机构 | 总分 | OPEN<br/>多轮开放 | OPT<br/>客观题 | 使用 |
|:---:|:---:|:---:|:---:|:---:|:---:|:---:|  
| - | GPT4-Turbo | OpenAI | 89.79 | 97.53 | 78.18 | API |
| - | GPT-4 | OpenAI | 75.14 | 73.01 | 78.33 | API |
| 🏅 |Yi-34B-Chat|	零一万物|	71.87 |	71.21 |	72.85 |	模型 |
| - | Claude2 | Anthropic | 60.62 | 57.82 | 64.82 | API |  
| - | GPT3.5-Turbo | OpenAI | 59.39 | 57.16 | 62.73 | API |
| 🥈 | XVERSE-13B-2-Chat | 元象科技 | 58.31 | 49.95 | 70.84 | 模型 |   
| 🥉 | Qwen-14B-Chat | 阿里巴巴 | 57.90 | 49.05 | 71.18 | API |
| 4 | Baichuan2-13B-Chat | 百川智能 | 56.33 | 50.33 | 65.33 | 模型 |
| 5 | ChatGLM3-6B | 清华&智谱 | 46.24 | 38.01 | 58.58 | 模型 |
| 6 | Chinese-Alpaca-2-13B | yiming cui | 43.42 | 38.09 | 51.42 | 模型 |
| - | Llama-2-13B-Chat | Meta | 31.47 | 28.67 | 35.67 | 模型 |

### 23-11月测评改进

    1. 本次测评中SuperCLUE-Open的超级模型（裁判模型）由10月的GPT4升级为能力更强的GPT4-Turbo，进一步提升开放主观题评估的精确性。
    
    2. 本次SuperCLUE-Open测评集总量由10月的3754道题扩展至4265道题。
    
    3. 与10月相比，本次测评新增了腾讯的混元、阿里云的通义千问2.0(v1030)、零一万物的Yi-34B-Chat、清华&智谱AI的ChatGLM3-Turbo和ChatGLM3-6B、
    元象科技的XVERSE-13B-2-Chat。

### 示例
#### 能力1：语义理解与抽取

这是一种语言能力，能够理解并解析输入的文字信息的含义。模型需要能够识别短语、句子、段落的含义，同时还要能从更大的文本块中抽取关键信息和主题。

##### 多轮对话示例

<img src="https://github.com/CLUEbenchmark/SuperCLUE/blob/main/resources/r2309/image_nlp.png"  width="100%" height="100%"></img>

注：本示例中可同时评测多轮对话能力

#### 能力2：AI agent（智能体）能力

AI agent（智能体）是当前与大语言模型相关的前沿研究热点，拥有类似贾维斯等科幻电影中人类超级助手的能力，可以根据需求自主的完成任务。

重点评估AI agent在【工具使用】和【任务规划】两个关键能力上的表现

##### 示例

<img src="https://github.com/CLUEbenchmark/SuperCLUE/blob/main/resources/r2309/image_agent.png"  width="100%" height="100%"></img>


#### 能力3：上下文对话

这是一种语言能力，需要理解并记住前面的对话信息，以便在回答中保持连贯性。这涉及到理解对话的整体流程和上下文环境，或生成相应的对话。

##### 示例

<img src="https://github.com/CLUEbenchmark/SuperCLUE/blob/main/resources/r2309/image_dial.png"  width="100%" height="100%"></img>

#### 能力4：生成与创作

这是一种语言能力，能够创造新的文本内容，如文章、文案、短故事、诗歌。这涉及到创造性地运用语言，同时还要考虑到风格、语境和目标读者。

##### 示例
<img src="https://github.com/CLUEbenchmark/SuperCLUE/blob/main/resources/r2309/image_generate.png"  width="100%" height="100%"></img>


#### 能力5：知识与百科

这是一种知识能力，能够像百科全书一样提供知识信息。这涉及到理解和回答关于广泛主题的问题，以及提供准确、详细和最新的信息。

##### 示例

<img src="https://github.com/CLUEbenchmark/SuperCLUE/blob/main/resources/r2309/image_knowledge.png"  width="100%" height="100%"></img>


#### 能力6：代码

这是一种专业能力，能够理解和生成编程代码。这涉及到理解多种编程语言的语法、结构和习惯，以及如何解决编程问题。

##### 多轮对话示例

<img src="https://github.com/CLUEbenchmark/SuperCLUE/blob/main/resources/r2309/image_code.png"  width="100%" height="100%"></img>

注：本示例中可同时评测多轮对话能力

#### 能力7：逻辑与推理

这是一种专业能力，能够理解和应用逻辑原则进行推理。这涉及到分析问题、识别问题及推理。

##### 示例

<img src="https://github.com/CLUEbenchmark/SuperCLUE/blob/main/resources/r2309/image_logic.png"  width="100%" height="100%"></img>


####  能力8：计算

这是一种专业能力，使其能够执行数学运算，如加法、减法、乘法和除法，甚至更复杂的数学问题。这涉及到理解数学问题的表述，以及如何步骤地解决这些问题。

##### 多轮对话示例

<img src="https://github.com/CLUEbenchmark/SuperCLUE/blob/main/resources/r2309/image_compute.png"  width="100%" height="100%"></img>

注：本示例中可同时评测多轮对话能力

####  能力9：角色扮演

这是一种感知能力，使其能够在特定的模拟环境或情景中扮演一个角色。这涉及到理解特定角色的行为、说话风格，以及在特定情境下的适当反应。

##### 示例

<img src="https://github.com/CLUEbenchmark/SuperCLUE/blob/main/resources/r2309/image_roleplay.png"  width="100%" height="100%"></img>


####   能力10：安全

这是一种安全能力，防止生成可能引起困扰或伤害的内容。这涉及到识别和避免可能包含敏感或不适当内容的请求，以及遵守用户的隐私和安全政策。

##### 示例

<img src="https://github.com/CLUEbenchmark/SuperCLUE/blob/main/resources/r2309/image_safety.png"  width="100%" height="100%"></img>

### 8月榜单更新情况
1.综合性：将OPEN多轮开放问题与OPT三大能力客观题进行了结合起来，作为8月榜单；

2.模型细节：Baichuan-13B-Chat使用了是最新的模型权重，具体见huggingface的权重；文心一言，OPT三大能力客观题使用的是API（Ernie-3.5-turbo）；
  360使用的是api版本；

3.模型更新：去除了一些前期大家比较关注但当前活跃度不高的模型，如MOSS，BELLE等；加入了一些如Qwen-7B-Chat和3个Llam2相关模型。
