# SuperCLUE
全球首个中文通用大模型综合性基准SuperCLUE

SuperCLUE: A Benchmark for Foundation Models in Chinese


<img src="https://github.com/CLUEbenchmark/SuperCLUE/blob/main/resources/superclue.jpg"  width="72%" height="72%"></img>

SuperCLUE基准计划按照月度进行更新，纳入更多可用中文大模型，欢迎联系与交流

## SuperCLUE是什么
中文通用大模型基准（SuperCLUE），是针对中文可用的通用大模型的一个测评基准。

它主要要回答的问题是：在当前通用大模型大力发展的情况下，中文大模型的效果情况。包括但不限于：这些模型哪些相对效果情况、相较于国际上的代表性模型做到了什么程度、
这些模型与人类的效果对比如何？

它尝试在一系列国内外代表性的模型上使用多个维度能力进行测试。SuperCLUE是中文语言理解测评基准（CLUE）基准是在通用人工智能时代的进一步发展。


## SuperCLUE的构成与特点
着眼于综合评价大模型的能力，使其能全面的测试大模型的效果，又能考察模型在中文上特有任务的理解和积累，我们对能力进行了划分。
SuperCLUE从三个不同的维度评价模型的能力：基础能力、专业能力和中文特性能力。
<img src="https://github.com/CLUEbenchmark/SuperCLUE/blob/main/resources/score.jpg"  width="85%" height="85%"></img>

#### 基础能力:

包括了常见的有代表性的模型能力，如语义理解、对话、逻辑推理、角色扮演、代码、生成与创作等10项能力。

#### 专业能力:

包括了中学、大学与专业考试，涵盖了从数学、物理、地理到社会科学等50多项能力。

#### 中文特性能力:

针对有中文特点的任务，包括了中文成语、诗歌、文学、字形等10项多种能力。


#### SuperCLUE的特点：
1）多个维度能力考察（3大类70+子能力）：从三个不同角度对中文大模型进行测试，以考察模型的综合能力；并且每一个子能力又含有十项或以上不同的细分能力。

2）自动化测评（一键测评）：通过自动化测评方式以相对客观形式测试不同模型的效果，可以一键对大模型进行测评。

3）广泛的代表性模型（9个模型）：选取了多个国内外有代表性的可用的模型进行测评，以反应国内大模型的发展现状并了解与国际领先模型的差距或相对优劣势。

4）人类基准：在通用人工智能发展的情况下，也提供了模型相对于人类效果的指标对比。


## SuperCLUE的数据集
1.基础能力（10项能力）：语义理解、生成与创作、闲聊、对话、百科与知识、逻辑与推理、计算能力、代码、角色模拟、对话安全
    
    示例：
    语义理解：
        她说话不算数，经常食言。她的说话不算数是什么意思？
         A. 她讲的话很含糊不清。
         B. 她说话不信守承诺
         C. 她说话很有说服力。
         D. 她的话很有条理。
         
    逻辑与推理：
        小明有一个兄弟，但是没有姐姐。以下哪个推论是正确的？
         A. 小明的兄弟有一个哥哥
         B. 小明的兄弟有一个弟弟
         C. 小明是独生子
         D. 无法确定小明的兄弟是哥哥还是弟弟
 
     

2.中文特性能力（10项能力）：成语、诗词、文学、字义理解、汉语句法分析、汉字字形和拼音理解、歇后语和谚语、对联、方言、古文
    
    示例：
    成语：
    选出下列句子中成语使用正确的一项
     A. 在北方剧场，蒙古国艺术团来哈演出，热情的观众袖手旁观。
     B. 他想得很多，办事非常周全，真是匠心独运。
     C. 他们同学三年，关系一直很好，两人相敬如宾，互相尊重。
     D. 人生的航船不会一帆风顺，我们要正视困难，敢与风浪搏击，就一定会达到胜利的彼岸。
     
    文学：
    下列有关名著的表述有误的一项是
     A. 《水浒传》给我们留下许多脍炙人口的故事，例如拳打镇关西、智取生辰纲、三打祝家庄、三调芭蕉扇等。
     B. 《西游记》中，孙悟空面对妖怪有时也会遇到麻烦。例如青牛怪有一个白森森的"金刚琢"，能把金箍棒一股脑儿套去，让孙悟空不得不另行设法。
     C.  鲁迅先生称《世说新语》为“一部名士底（的）教科书”。其中的“谢女咏雪”、“子猷访戴”等故事，成为后世诗文常用典故。
     D. 《朝花夕拾》中，鲁迅回忆那个具有人情味的鬼----无常时，时不时加进几句对现实所谓正人君子的讽刺，虚幻的无常给予当时鲁迅寂寞悲凉的心些许的安慰。
         
     
3.专业能力（50+能力）：抽象代数、天文学、临床知识、大学生物学、大学计算机科学、大学数学、高中化学、高中物理、机器学习、营养、专业会计、职业心理学等
    
    示例：
    物理：
    一个质量为2千克的物体受到三个外力的作用，每个外力的大小都是4牛。下列哪一个不可能是物体的加速度?
     A. 0米/秒^2
     B. 2米/秒^2
     C. 4米/秒^2
     D. 8米/秒^2
     
    天文学：
    什么定义了恒星周围的宜居带？
     A. 恒星周围的区域，在行星表面上液态水可能存在的区域。
     B. 恒星周围的区域，人类可以生存的区域。
     C. 恒星周围的区域，紫外线辐射不会破坏行星表面上的生物体。
     D. 恒星周围的区域，生命存在的区域。
    
## SuperCLUE全自动测评过程：
    1、统一prompt：针对每一个题目，构造了统一的prompt供模型和人类使用；
    2、预测：系统使用模型进行预测，要求模型选取ABCD中一个唯一的选项；
    3、打分：如果模型的回答不是标准的答案，而是一段文字，系统会采取特定的策略自动提取出模型的答案。该策略结合模型的表现进行优化和完善。
       （注：当无法提取有效答案的时候，则表明模型没有按照人类做题的要求，未正确理解指令，则认为模型回答错误。）
       
   由于此次为SuperCLUE首次全自动测评，为了谨慎起见，全部答案事后已由多位人类进行交叉复核，与自动测评结果基本一致。

## 人类基准测评
针对所有主任务和子任务题目，都会有三位独立的人类测评员根据题目做答。人类测评结果，采用多数投票方式进行汇总，作为人类基准分数。


## 实验分析
从人类测评角度看，基础能力（98%）+中文特性（95%），都达到了非常高的水平。除GPT-4外，大幅超过了其他的大模型（如在基础能力上超过其他模型20多个点）。

从模型角度上看，GPT4.0模型在基础能力+中文特性上已经达到了优秀的程度（80.95）；同时国内的部分模型（如讯飞星火、MinMax）在这两项能力上平均后的效果接近ChatGPT3.5的水平。
效果最差的模型，是没有在中文上针对性训练的通用模型Vicuna-13B（46.52）.


综合的看，国际先进模型效果具有较大的领先性；同时国产GPT模型也有不俗的表现，甚至部分模型在一些能力上有惊艳的表现。
从能力角度上看，在基础能力上，除个别模型外（Vicuna-13B）外都达到或超过了基础能力的及格线：代表在各类常见任务上多数都具备在工作或生活中的使用价值；
在中文特性能力上，不同模型的差距则非常明显；一些模型没有达标（及格线），而GPT4则达到了优秀的程度（79.40）；MinMax的模型效果（74.97）较好，甚至超过了ChatGPT3.5的水平（64.37）。
这或许意味着在不久的将来，国产类GPT模型不仅有望在通用人工智能中追平国际先进水平，甚至还有机会实现部分场景或能力的超越。


## SuperCLUE的测试结果
四个表格：汇总表、基础能力表、专业能力表、中文特性表

#####  排行榜会定期更新           数据来源: www.CLUEbenchmarks.com               

#### 汇总表(v1.0版)
| 模型   | 基础能力+中文特性     | 基础能力  |中文特性能力| 专业能力  | 三项能力（汇总）    
| -------- | ---------- | ---- | ---------- | -------- | ---------- | 
| <a href="Vicuna-13B"></a>  Vicuna-13B   |46.52   | 59.13 |33.90 |Comming  |Comming  |
| <a href="MOSS-16B"></a>   Moss-16B      | 58.27 | 63.73|52.80 |31.54  |49.36  |
| <a href="ChatGLM-6B"></a>   ChatGLM-6B     |61.82   | 66.77 |56.87  |32.56?  |52.07  |
| <a href="文心一言"></a>  文心一言     |67.44  | 69.97 |64.90  |-  |-  |
| <a href="MinMax"></a>  MinMax     | 72.94  | 70.90 |74.97  |-  |-  |
| <a href="ChatGPT-3.5"></a>   ChatGPT-3.5   |73.27   | 82.17 |64.37  |57.1 |67.79  |
| <a href="GPT-4.0"></a>  GPT-4.0    |**81.79** | **84.17** |**79.40**  |- |-  |

#### 基础能力表(v1.0版)

| 任务类型 | ChatGPT3.5 | GPT4 | ChatGLM-6B | Moss-16B | Vicuna-13B | 文心一言 | MinMax |
| -------- | ---------- | ---- | ---------- | -------- | ---------- | -------- | ------ |
| 语义理解 | 100.00     | **90.70** | 70.00      | 50.00    | 70.00      | 70.30    | 70.30  |
| 生成与创作 | 77.30      | **82.30** | 68.00      | 63.30    | 62.30      | 68.70    | 63.30  |
| 闲聊     | 75.70      | **79.30** | 74.70      | 65.70    | 72.70      | 78.30    | 76.00  |
| 对话     | 76.00      | **84.30** | 80.00      | 76.70    | 74.00      | 68.00    | 81.00  |
| 百科与知识 | **80.30**      | 79.00 | 79.30      | 71.00    | 38.00      | 79.30    | 79.70  |
| 逻辑与推理 | 77.30      | **84.70** | 24.30      | 28.00    | 30.70      | 35.00    | 45.70  |
| 计算能力 | 88.00      | **92.30** | 46.30      | 54.00    | 32.70      | 82.00    | 64.70  |
| 代码     | 85.70      | **89.00** | 68.30      | 81.70    | 78.00      | 80.00    | 76.30  |
| 角色模拟 | 82.00      | **86.00** | 80.30      | 78.00    | 74.30      | 77.30    | 78.30  |
| 安全     | **79.30**      | 74.00 | 76.30      | 69.00    | 58.70      | 60.70    | 73.70  |
| 总分     | 82.17     | **84.17** | 66.77     | 63.73   | 59.13     | 69.97   | 70.90 |

#### 中文特性能力表(v1.0版)
|  | ChatGPT3.5 | GPT-4 | ChatGLM | MOSS-16B | Vicuna-13B | 文心一言 | MinMax |
| --- | --- | --- | --- | --- | --- | --- | --- |
| 1.成语 | 64.0 | **74.7** | 80.7 | 59.0 | 34.0 | 72.0 | 76.7 |
| 2.对联 | 64.0 | **73.7** | 45.0 | 52.0 | 16.0 | 51.3 | 66.3 |
| 3.方言 | 67.3 | **81.3** | 43.7 | 23.3 | 26.0 | 54.7 | 70.0 |
| 4.古文 | 60.7 | **76.3** | 50.7 | 51.3 | 34.0 | 70.3 | 75.7 |
| 5.句法 | 69.7 | **92.0** | 76.7 | 64.7 | 64.7 | 60.0 | 83.7 |
| 6.字形 | 81.7 | **94.0** | 47.0 | 57.0 | 31.7 | 84.0 | 83.3 |
| 7.诗词 | 50.3 | 74.0 | 55.3 | 63.0 | 28.0 | 63.3 | **77.3** |
| 8.文学 | 66.3 | **77.7** | 68.7 | 60.0 | 32.0 | 69.0 | **77.7** |
| 9.歇后语 | 58.0 | 68.3 | 54.7 | 41.7 | 32.3 | 63.0 | **71.3** |
| 10.字义 | 61.7 | **82.0** | 46.3 | 56.0 | 40.3 | 61.3 | 67.7 |
| 总分 | 64.37 | **79.40** | 56.87 | 52.80 | 33.90 | 64.90 | 74.97 |

    注：由于文心一言和讯飞星火未提供测试API，由人工录入问题进行结果评测


## SuperCLUE的不足与局限
1. 基础能力、中文特性能力：虽然每一部分都包含了10类子能力，但这两个能力的总数据量比较少，可能存在需要扩充数据集的问题。
2. 选取模型的不完全：我们测试了9个模型，但还存在着更多的可用中文大模型。需要后续进一步添加并测试；有的模型由于没有广泛对外提供服务，我们没能获取到可用的测试版本。
3. 选取的能力范围：我们尽可能的全面、综合衡量模型的多维度的能力，但是可能有一些模型能力没有在我们的考察范围内。后续也存在的扩大考察范围的可能。

## SuperCLUE的讨论与交流
SuperCLUE交流群
