# SuperCLUE

中文通用大模型综合性基准SuperCLUE

<a href='https://www.superclueai.com' target="__blank">SuperCLUE中文大模型测评基准最新榜单</a>

官网地址：<a href='https://www.cluebenchmarks.com/superclue.html' target="__blank">www.cluebenchmarks.com/superclue.html</a>

技术报告：<a href='https://arxiv.org/abs/2307.15020' target="__blank">SuperCLUE: A Comprehensive Chinese Large Language Model Benchmark</a>


【2023-12-27】 <a href='https://mp.weixin.qq.com/s/PycSpCCREBgB0tEy3csPKQ'>《中文大模型基准测评报告2023年度报告》发布</a>

【2023-12-28】 发布SuperCLUE-2023年12月榜单


【2023-10-19】 <a href='https://www.cluebenchmarks.com/superclue_agent.html' target="__blank">SuperCLUE-Agent：Agent智能体中文原生任务评估基准</a>


【2023-9-12】 <a href='https://github.com/CLUEbenchmark/SuperCLUE-safety' target="__blank">SuperCLUE-Safety：中文大模型多轮对抗安全基准</a>


【2023-9-26】，SuperCLUE发布中文大模型9月榜单。

SuperCLUE是一个综合性大模型评测基准，本次评测主要聚焦于大模型的四个能力象限，包括语言理解与生成、专业技能与知识、Agent智能体和安全性，进而细化为12项基础能力。

相比与上月，新增了AI Agent智能体

<img src="https://github.com/CLUEbenchmark/SuperCLUE/blob/main/resources/superclue_idea2.png"  width="90%" height="90%"></img>

### SuperCLUE能力评估结构图
<img src="https://github.com/CLUEbenchmark/SuperCLUE/blob/main/resources/category09.png"  width="60%" height="60%"></img>

### SuperCLUE多维度测评方案
<img src="https://github.com/CLUEbenchmark/SuperCLUE/blob/main/resources/r2309/superclue_mlitisystem.png"  width="90%" height="90%"></img>


### 为什么新增AI Agent智能体能力？

AI agent（智能体）是当前与大语言模型相关的前沿研究热点，拥有类似贾维斯等科幻电影中人类超级助手的能力，可以根据需求自主的完成任务。
然而，面向AI agent智能体，缺乏针对中文大模型的广泛评估。为了解决这一问题，我们在SuperCLUE新的榜单中新增了AI agent智能体能力的测评。
这个榜单将重点评估AI agent在【工具使用】和【任务规划】两个关键能力上的表现，这项工作旨在为评估中文大模型作为智能体的表现提供一个基础和可能。

### SuperCLUE总排行榜（2023年12月）

| 排名 | 模型 | 机构 | 总分 | OPEN多轮<br/>开放问题 | OPT三大<br/>能力客观题 | 使用 |
|:-:|:-:|:-:|:-:|:-:|:-:|:-:|  
| -|GPT4-Turbo | OpenAI | 90.63 | 90.89 | 90.03 | API |
| -|GPT4(网页) | OpenAI | 83.92 | 80.76 | 91.28 | 网页 |
| -|GPT4(API) | OpenAI | 79.84 | 76.24 | 88.24 | API |
| 🏅️ | 文心一言4.0(API) | 百度 | 79.02 | 75.00 | 88.38 | API |
| 🥈 | 通义千问2.0 | 阿里巴巴 | 76.54 | 71.78 | 87.64 | API |  
| 🥉 | AndesGPT | OPPO | 75.04 | 70.01 | 86.76 | API |
| 4 | 智谱清言 | 清华&智谱 | 74.11 | 69.91 | 83.92 | 网页 |
| 5 | Moonshot(KimiChat) | 月之暗面 | 71.92 | 67.25 | 82.81 | 网页 |
| - | 文心一言4.0(网页) | 百度 | 70.28 | 62.59 | 88.22 | 网页 |
| 6 | Qwen-72B-Chat | 阿里巴巴 | 69.69 | 62.31 | 86.90 | API |  
| 7 | 序列猴子 | 出门问问 | 68.98 | 61.01 | 87.59 | API |
| 8 | Yi-34B-Chat | 零一万物 | 68.46 | 61.99 | 83.56 | 模型 |
| 9 | PCI-TransGPT | 佳都科技 | 68.33 | 60.41 | 86.81 | API |
| 9 | 360GPT_Pro | 360 | 68.32 | 61.36 | 84.56 | API |
| - | Claude2 | Anthropic | 67.43 | 65.14 | 72.77 | API |
| 11 | 云雀大模型(豆包) | 字节跳动 | 66.35 | 58.53 | 84.60 | 网页 | 
| - | Gemini-pro | Google | 65.29 | 59.33 | 79.20 | API |
| - | GPT3.5-Turbo | OpenAI | 61.44 | 55.63 | 74.98 | API |
| 12 | Qwen-14B-Chat | 阿里巴巴 | 61.27 | 52.04 | 82.81 | API |
| 13 | Baichuan2-13B-Chat | 百川智能 | 61.12 | 54.45 | 76.67 | 模型 |
| 14 | XVERSE-13B-2-Chat | 元象科技 | 60.46 | 53.00 | 77.87 | 模型 |
| 15 | 讯飞星火V3.0 | 科大讯飞 | 59.33 | 51.74 | 77.03 | API |
| 16 | Minimax(应事) | 稀宇科技 | 58.91 | 50.00 | 79.69 | 网页 |
| 17 | ChatGLM3-6B | 清华&智谱 | 49.50 | 42.30 | 66.31 | 模型 |
| 18 | Chinese-Alpaca-2-13B | yiming cui | 45.36 | 38.91 | 60.40 | 模型 |
| - | Llama_2_13B_Chat | Meta | 37.36 | 34.91 | 43.09 | 模型 |

注：处于前列的模型，如果分数比较接近（小于0.03分），在排名时会被记为并列的名称。

### SuperCLUE-OPEN多轮开放问题排行榜（2023年12月）
| 排名 | 模型 | 机构 | OPEN多轮<br/>开放问题 | 语言<br/>与知识 | 专业<br/>与技能 | 工具<br/>使用 | 传统<br/>安全 | 使用 |
|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:| 
| - | GPT4-Turbo | OpenAI | 90.89 | 90.21 | 97.00 | 100.00 | 62.75 | API |
| - | GPT4(网页) | OpenAI | 80.76 | 79.49 | 82.87 | 94.63 | 64.71 | 网页 |
| - | GPT4(API) | OpenAI | 76.24 | 73.96 | 81.15 | 93.34 | 53.92 | API |
| 🏅️ | 文心一言4.0(API) | 百度 | 75.00 | 69.54 | 79.62 | 80.92 | 68.00 | API |
| 🥈 | 通义千问2.0 | 阿里巴巴 | 71.78 | 71.58 | 73.40 | 76.32 | 52.94 | API | 
| 🥉 | AndesGPT | OPPO | 70.01 | 72.23 | 68.80 | 70.71 | 55.88 | API |
| 4 | 智谱清言 | 清华&智谱 | 69.91 | 66.98 | 68.63 | 83.78 | 65.31 | 网页 |
| 5 | Moonshot(KimiChat) | 月之暗面 | 67.25 | 69.72 | 72.57 | 62.19 | 43.14 | 网页 |  
| - | Claude2 | Anthropic | 65.14 | 55.28 | 73.27 | 65.13 | 83.00 | API |
| - | 文心一言4.0(网页) | 百度 | 62.59 | 65.05 | 63.26 | 47.37 | 64.00 | 网页 |
| 6 | Qwen-72B-Chat | 阿里巴巴 | 62.31 | 59.43 | 65.59 | 60.67 | 52.00 | API |
| 7 | Yi-34B-Chat | 零一万物 | 61.99 | 63.90 | 54.55 | 71.05 | 65.31 | 模型 |
| 8 | 360GPT_Pro | 360 | 61.36 | 62.09 | 58.70 | 69.33 | 60.00 | API |  
| 9 | 序列猴子 | 出门问问 | 61.01 | 65.81 | 59.99 | 56.58 | 45.10 | API |
| 10 | PCI-TransGPT | 佳都科技 | 60.41 | 60.39 | 61.56 | 64.66 | 50.98 | API |
| - | Gemini-pro | Google | 59.33 | 60.50 | 61.43 | 46.53 | 62.50 | API |
| 11 | 云雀大模型(豆包) | 字节跳动 | 58.53 | 57.75 | 56.42 | 55.26 | 67.65 | 网页 |
| - | GPT3.5-Turbo | OpenAI | 55.63 | 55.30 | 56.24 | 55.26 | 52.00 | API |  
| 12 | Baichuan2-13B-Chat | 百川智能 | 54.45 | 57.35 | 48.69 | 56.58 | 54.90 | 模型 |
| 13 | XVERSE-13B-2-Chat | 元象科技 | 53.00 | 54.63 | 45.82 | 63.33 | 57.84 | 模型 |
| 14 | Qwen-14B-Chat | 阿里巴巴 | 52.04 | 54.29 | 48.38 | 45.33 | 56.86 | API |
| 15 | 讯飞星火V3.0 | 科大讯飞 | 51.74 | 57.40 | 48.41 | 44.00 | 43.14 | API |
| 16 | Minimax(应事) | 稀宇科技 | 50.00 | 53.54 | 45.05 | 40.13 | 50.00 | 网页 | 
| 17 | ChatGLM3-6B | 清华&智谱 | 42.30 | 46.67 | 36.15 | 34.25 | 53.92 | 模型 |
| 18 | Chinese-Alpaca-2-13B | yiming cui | 38.91 | 46.46 | 29.35 | 27.63 | 46.94 | 模型 |
| - | Llama_2_13B_Chat | Meta | 34.91 | 36.55 | 30.21 | 32.67 | 53.92 | 模型 |

### SuperCLUE-OPT三大能力客观题排行榜（2023年12月）

| 排名 | 模型 | 机构 | OPT分数 | 基础<br/>能力 | 中文<br/>特性 | 学术专<br/>业能力 | 使用 |
|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|  
| - | GPT4(网页) | OpenAI | 91.28 | 97.62 | 82.38 | 93.85 | 网页 |
| - | GPT4-Turbo | OpenAI | 90.03 | 96.99 | 79.16 | 93.93 | API |
| 🏅️ | 文心一言4.0(API) | 百度 | 88.38 | 91.65 | 86.18 | 87.32 | API |  
| - | GPT4(API) | OpenAI | 88.24 | 92.92 | 81.84 | 89.95 | API |
| - | 文心一言4.0(网页) | 百度 | 88.22 | 76.48 | 78.32 | 57.05 | 网页 |
| 🥈 | 通义千问2.0 | 阿里巴巴 | 87.64 | 78.65 | 81.28 | 63.48 | API |
| 🥉 | 序列猴子 | 出门问问 | 87.59 | 91.46 | 80.28 | 90.57 | API |
| 4 | Qwen-72B-Chat | 阿里巴巴 | 86.90 | 92.21 | 76.65 | 91.05 | API |  
| 5 | PCI-TransGPT | 佳都科技 | 86.81 | 90.76 | 80.88 | 88.42 | API |
| 6 | AndesGPT | OPPO | 86.76 | 92.55 | 76.17 | 90.81 | API |
| 7 | 云雀大模型(豆包) | 字节跳动 | 84.60 | 88.75 | 70.89 | 93.06 | 网页 |
| 8 | 360GPT_Pro | 360 | 84.56 | 91.70 | 73.32 | 87.93 | API |
| 9 | 智谱清言 | 清华&智谱 | 83.92 | 89.14 | 73.10 | 88.72 | 网页 |
| 10 | Yi-34B-Chat | 零一万物 | 83.56 | 86.90 | 72.81 | 90.12 | 模型 |
| 11 | Qwen-14B-Chat | 阿里巴巴 | 82.81 | 91.14 | 68.67 | 87.31 | API |  
| 12 | Moonshot(KimiChat) | 月之暗面 | 82.81 | 87.77 | 73.39 | 86.41 | 网页 |
| 13 | Minimax(应事) | 稀宇科技 | 79.69 | 86.52 | 66.18 | 85.18 | 网页 |  
| - | Gemini-pro | Google | 79.20 | 83.72 | 70.78 | 82.51 | API |
| 14 | XVERSE-13B-2-Chat | 元象科技 | 77.87 | 84.46 | 62.96 | 83.85 | 模型 |
| 15 | 讯飞星火V3.0 | 科大讯飞 | 77.03 | 84.04 | 63.43 | 82.48 | API |
| 16 | Baichuan2-13B-Chat | 百川智能 | 76.67 | 80.61 | 63.79 | 84.50 | 模型 |
| - | GPT3.5-Turbo | OpenAI | 74.98 | 83.78 | 62.83 | 77.60 | API |
| - | Claude2 | Anthropic | 72.77 | 82.13 | 65.83 | 70.10 | API |
| 17 | ChatGLM3-6B | 清华&智谱 | 66.31 | 72.63 | 54.05 | 71.38 | 模型 |
| 18 | Chinese-Alpaca-2-13B | yiming cui | 60.40 | 70.39 | 47.75 | 62.31 | 模型 |
| - | Llama_2_13B_Chat | Meta | 43.09 | 50.41 | 37.22 | 41.48 | 模型 |

### SuperCLUE十大基础能力排行榜（2023年12月）

| 模型 | 计算 | 逻辑<br/>推理 | 代码 | 知识<br/>百科 | 语言<br/>理解 | 生成<br/>创作 | 对话 | 角色<br/>扮演 | 工具<br/>使用 | 传统<br/>安全 |
|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|  
| GPT4-Turbo | 97.24 | 97.59 | 96.18 | 89.62 | 87.82 | 89.93 | 89.22 | 94.46 | 100.00 | 62.75 |
| GPT4(网页) | 81.16 | 85.62 | 81.84 | 79.17 | 81.91 | 78.91 | 78.38 | 79.09 | 94.63 | 64.71 |
| 文心一言4.0(API) | 77.84 | 87.84 | 73.19 | 98.63 | 71.93 | 66.36 | 57.03 | 53.77 | 80.92 | 68.00 |
| GPT4(API) | 77.60 | 85.37 | 80.49 | 78.08 | 73.04 | 72.73 | 75.78 | 70.17 | 93.34 | 53.92 |
| Claude2 | 70.10 | 80.14 | 69.57 | 62.33 | 72.32 | 39.81 | 54.76 | 47.17 | 65.13 | 83.00 |
| 通义千问2.0 | 70.10 | 73.29 | 76.81 | 93.15 | 71.93 | 62.73 | 68.75 | 61.32 | 76.32 | 52.94 |
| 智谱清言 | 69.07 | 77.40 | 59.42 | 89.73 | 64.91 | 61.11 | 57.81 | 61.32 | 83.78 | 65.31 |  
| Qwen-72B-Chat | 68.56 | 68.06 | 60.14 | 95.89 | 63.16 | 42.59 | 48.44 | 47.06 | 60.67 | 52.00 |
| Moonshot(KimiChat) | 68.54 | 79.65 | 69.52 | 100.00 | 66.78 | 59.65 | 61.33 | 60.84 | 62.19 | 43.14 |
| AndesGPT | 62.59 | 72.26 | 71.55 | 88.36 | 74.82 | 64.23 | 68.56 | 65.19 | 70.71 | 55.88 |
| GPT3.5-Turbo | 60.31 | 54.05 | 54.35 | 60.27 | 59.82 | 55.45 | 50.00 | 50.96 | 55.26 | 52.00 |
| 360GPT_Pro | 56.43 | 64.97 | 54.70 | 93.84 | 62.79 | 55.73 | 55.75 | 42.32 | 69.33 | 60.00 |
| Gemini-pro | 56.32 | 58.45 | 69.53 | 73.91 | 61.61 | 54.63 | 52.54 | 59.80 | 46.53 | 62.50 |
| 序列猴子 | 55.38 | 67.12 | 57.48 | 92.47 | 58.77 | 57.81 | 56.75 | 63.27 | 56.58 | 45.10 |
| 云雀大模型(豆包) | 54.69 | 68.92 | 45.65 | 86.99 | 56.14 | 48.18 | 53.12 | 44.34 | 55.26 | 67.65 |
| Yi-34B-Chat | 50.00 | 64.38 | 49.28 | 88.36 | 65.18 | 62.73 | 58.87 | 44.34 | 71.05 | 65.31 |
| PCI-TransGPT | 49.99 | 72.19 | 62.49 | 82.88 | 60.45 | 57.18 | 54.76 | 46.69 | 64.66 | 50.98 |
| Qwen-14B-Chat | 49.48 | 56.85 | 38.81 | 76.71 | 61.40 | 45.45 | 43.75 | 44.12 | 45.33 | 56.86 |
| 文心一言4.0(网页) | 48.45 | 79.73 | 61.59 | 97.26 | 65.79 | 60.91 | 53.17 | 48.11 | 47.37 | 64.00 |
| XVERSE-13B-2-Chat | 43.30 | 50.68 | 43.48 | 72.92 | 57.02 | 47.27 | 46.88 | 49.06 | 63.33 | 57.84 |  
| Minimax(应事) | 43.30 | 61.43 | 30.43 | 100.00 | 55.26 | 33.33 | 45.16 | 33.96 | 40.13 | 50.00 |
| Baichuan2-13B-Chat | 40.62 | 66.22 | 39.23 | 78.77 | 53.51 | 52.78 | 55.47 | 46.23 | 56.58 | 54.90 |
| 讯飞星火V3.0 | 38.54 | 57.43 | 49.26 | 83.57 | 62.28 | 47.17 | 46.83 | 47.17 | 44.00 | 43.14 |
| ChatGLM3-6B | 34.74 | 41.10 | 32.61 | 56.94 | 54.39 | 38.18 | 41.41 | 42.45 | 34.25 | 53.92 |
| Llama_2_13B_Chat | 24.74 | 40.54 | 25.36 | 36.11 | 41.07 | 43.64 | 28.91 | 33.02 | 32.67 | 53.92 |  
| Chinese-Alpaca-2-13B | 22.40 | 45.21 | 20.45 | 51.37 | 51.75 | 39.09 | 47.66 | 42.45 | 27.63 | 46.94 |


### SuperCLUE开源模型排行榜（2023年12月）

| 排名 | 模型 | 机构 | 总分 | OPEN<br/>多轮开放问题 | OPT<br/>三大能力客观题 |
|:-:|:-:|:-:|:-:|:-:|:-:|  
| 🏅️ | Qwen-72B-Chat | 阿里巴巴 | 69.69 | 62.31 | 86.90 |
| 🥈 | Yi-34B-Chat | 零一万物 | 68.46 | 61.99 | 83.56 |
| 🥉 | Qwen-14B-Chat | 阿里巴巴 | 61.27 | 52.04 | 82.81 |
| 4 | Baichuan2-13B-Chat | 百川智能 | 61.12 | 54.45 | 76.67 |
| 5 | XVERSE-13B-2-Chat | 元象科技 | 60.46 | 53.00 | 77.87 |
| 6 | ChatGLM3-6B | 清华&智谱 | 49.50 | 42.30 | 66.31 |
| 7 | Chinese-Alpaca-2-13B | yiming cui | 45.36 | 38.91 | 60.40 |
| - | Llama_2_13B_Chat | Meta | 37.36 | 34.91 | 43.09 |

### 23-11月测评改进

    1. 本次测评中SuperCLUE-Open的超级模型（裁判模型）由10月的GPT4升级为能力更强的GPT4-Turbo，进一步提升开放主观题评估的精确性。
    
    2. 本次SuperCLUE-Open测评集总量由10月的3754道题扩展至4265道题。
    
    3. 与10月相比，本次测评新增了腾讯的混元、阿里云的通义千问2.0(v1030)、零一万物的Yi-34B-Chat、清华&智谱AI的ChatGLM3-Turbo和ChatGLM3-6B、
    元象科技的XVERSE-13B-2-Chat。

### 示例
#### 能力1：语义理解与抽取

这是一种语言能力，能够理解并解析输入的文字信息的含义。模型需要能够识别短语、句子、段落的含义，同时还要能从更大的文本块中抽取关键信息和主题。

##### 多轮对话示例

<img src="https://github.com/CLUEbenchmark/SuperCLUE/blob/main/resources/r2309/image_nlp.png"  width="100%" height="100%"></img>

注：本示例中可同时评测多轮对话能力

#### 能力2：AI agent（智能体）能力

AI agent（智能体）是当前与大语言模型相关的前沿研究热点，拥有类似贾维斯等科幻电影中人类超级助手的能力，可以根据需求自主的完成任务。

重点评估AI agent在【工具使用】和【任务规划】两个关键能力上的表现

##### 示例

<img src="https://github.com/CLUEbenchmark/SuperCLUE/blob/main/resources/r2309/image_agent.png"  width="100%" height="100%"></img>


#### 能力3：上下文对话

这是一种语言能力，需要理解并记住前面的对话信息，以便在回答中保持连贯性。这涉及到理解对话的整体流程和上下文环境，或生成相应的对话。

##### 示例

<img src="https://github.com/CLUEbenchmark/SuperCLUE/blob/main/resources/r2309/image_dial.png"  width="100%" height="100%"></img>

#### 能力4：生成与创作

这是一种语言能力，能够创造新的文本内容，如文章、文案、短故事、诗歌。这涉及到创造性地运用语言，同时还要考虑到风格、语境和目标读者。

##### 示例
<img src="https://github.com/CLUEbenchmark/SuperCLUE/blob/main/resources/r2309/image_generate.png"  width="100%" height="100%"></img>


#### 能力5：知识与百科

这是一种知识能力，能够像百科全书一样提供知识信息。这涉及到理解和回答关于广泛主题的问题，以及提供准确、详细和最新的信息。

##### 示例

<img src="https://github.com/CLUEbenchmark/SuperCLUE/blob/main/resources/r2309/image_knowledge.png"  width="100%" height="100%"></img>


#### 能力6：代码

这是一种专业能力，能够理解和生成编程代码。这涉及到理解多种编程语言的语法、结构和习惯，以及如何解决编程问题。

##### 多轮对话示例

<img src="https://github.com/CLUEbenchmark/SuperCLUE/blob/main/resources/r2309/image_code.png"  width="100%" height="100%"></img>

注：本示例中可同时评测多轮对话能力

#### 能力7：逻辑与推理

这是一种专业能力，能够理解和应用逻辑原则进行推理。这涉及到分析问题、识别问题及推理。

##### 示例

<img src="https://github.com/CLUEbenchmark/SuperCLUE/blob/main/resources/r2309/image_logic.png"  width="100%" height="100%"></img>


####  能力8：计算

这是一种专业能力，使其能够执行数学运算，如加法、减法、乘法和除法，甚至更复杂的数学问题。这涉及到理解数学问题的表述，以及如何步骤地解决这些问题。

##### 多轮对话示例

<img src="https://github.com/CLUEbenchmark/SuperCLUE/blob/main/resources/r2309/image_compute.png"  width="100%" height="100%"></img>

注：本示例中可同时评测多轮对话能力

####  能力9：角色扮演

这是一种感知能力，使其能够在特定的模拟环境或情景中扮演一个角色。这涉及到理解特定角色的行为、说话风格，以及在特定情境下的适当反应。

##### 示例

<img src="https://github.com/CLUEbenchmark/SuperCLUE/blob/main/resources/r2309/image_roleplay.png"  width="100%" height="100%"></img>


####   能力10：安全

这是一种安全能力，防止生成可能引起困扰或伤害的内容。这涉及到识别和避免可能包含敏感或不适当内容的请求，以及遵守用户的隐私和安全政策。

##### 示例

<img src="https://github.com/CLUEbenchmark/SuperCLUE/blob/main/resources/r2309/image_safety.png"  width="100%" height="100%"></img>


## 讨论、测评与交流

<br/>SuperCLUE-Agent榜单会定期进行更新，会纳入更多可用中文大模型。欢迎对大模型评测感兴趣的个人和机构联系与交流。<br/><br/>

<br/><h2 id="discuss">讨论交流与使用</h2>
  <img src="https://github.com/CLUEbenchmark/SuperCLUE-Agent/blob/main/resources/img/brightmart_s.jpeg"  width="30%" height="30%"></img>
</p> 

